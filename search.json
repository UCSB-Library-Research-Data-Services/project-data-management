[
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Data Management Plan",
    "section": "",
    "text": "In a nutshell, your goal as a Data Manager is to organize your team in a way that will let you document and preserve your work - including raw and derived data when possible. When delivering a project to a client, it is important to ensure the client can understand and reuse the products (code, data, apps) you have developed. For those reasons, more and more funders require a data management plan as part of their proposal submission process; therefore, it is a great skill to develop.\nHaving a plan to manage your data will save you from some potential painful hiccups and time as you progress through your project data life cycle. In other words, it is time well spent to develop your data management plan, and the earlier in your project, the better you have a good sense of how you will manage your data. The discussion with your team about what should be included in the plan is as important as the plan itself since the questions you will have to answer will help you think more about your data (e.g., type, size, processing methods, etc.) and assign roles and responsibilities among project members.\nYour overarching goal is to archive and share your data in a publicly accessible data repository such as Dryad as your project is completed or important milestones are achieved. For your work to be reproducible, metadata and documentation must also be developed, and the scripts you have developed for your analysis. Here is an example of a previous group archive: https://doi.org/10.25349/D97G9Z – especially look at the README.md describing the content.\nBefore writing your plan, we recommend you get familiar with the FAIR and CARE principles to guide your process.\nThose two principles should be the overarching guidelines that will guide the development of your data management plan."
  },
  {
    "objectID": "plan.html#developing-your-data-management-plan-dmp",
    "href": "plan.html#developing-your-data-management-plan-dmp",
    "title": "Data Management Plan",
    "section": "Developing your Data Management Plan (DMP)",
    "text": "Developing your Data Management Plan (DMP)\nWhen developing your data management plan, we recommend using the FAIR & CARE principles as guidance to maximize the reusability of your data by you, your collaborators, other researchers, and future-you. Your plan should ensure that detailed documentation adopting existing standards is developed during the entire duration of your project (don’t wait until the very end!!) and that this documentation is archived along with your data and code in a publicly accessible data repository will set you up for success.\n\n\n\nsource: https://www.library.ucsb.edu/sites/default/files/dls-n04-2021-fair-navy.pdf\n\n\nBelow is a set of questions that will help your team think about the data and resources you will need along your project’s data lifecycle.\n\nDescribing the research data: Provide a description of the data the group will collect or re-use, including the file types, data set size, the number of expected files or sets, content, and source of the data (creator and method of collection).\n\nWhat data are needed?\nAre such data available?\nWhen and how will the data be acquired?\nWho will be doing what?\n\nData formats:\n\nAre there any standard formats in the specific research field for managing or disseminating the data sets that have been identified (e.g., XML, ASCII, CSV, .shp, .gdb, GeoTIFF)?\nWho from the group will have responsibility for ensuring that data standards are properly applied, and data are properly formatted?\n\nMetadata: Metadata is documentation that helps make data sets reusable. Think about what details someone would need in order to be able to understand and use these files. For example, perhaps a readme.txt file is necessary to explain variables, the structure of the files, etc. In addition, it is recommended to leverage metadata disciplinary standards, including ontologies and vocabularies. Here is a good resource for metadata standards in environmental sciences. When applicable, also describe other scientific products - models, scripts, and/or workflows - your group will be producing using README files and documenting your code.\nData sharing and access The data may have significant value for other researchers beyond this project, and sharing this data is part of the group’s responsibility as members of the scientific community. Specify the extent to which data can be reused, including any access limitations. List any proprietary software that might be needed to read the files. If some data is not shareable due to confidentiality, non-disclosure agreements (NDA), or disclosure risk, state such limitations and the rationale behind them.\nIntellectual property and re-use: If data were collected from the client organization, does the group have the right to redistribute it? If so, are there any restrictions on redistribution? If the group created its data files, would it assign a Creative Commons license to its data?\nData archiving and preservation: Throughout the project, the group may produce a large number of files. At the end of the project, groups must submit data produced by the project (except data protected by non-disclosure agreements) and when relevant raw data as well. Not all data needs to be saved. Here are some questions to ask yourselves:\n\nIf another researcher wanted to replicate the group’s work or re-use the group’s data, what data and documentation would be required for them to do so?\n\nWhere will the data and metadata be stored after the project is completed?\nIs there a subject-specific and/or open-access repository that is appropriate for the data?\n\n\nOne advantage to depositing your data in a data repository is that you can get a DOI that lets you easily share and cite your data. Most of the data repositories also track views, downloads, and citations for your data archive, which can be used as a metric or a proxy for research impact.\n\nWant to know more?\n\nMore extensive guidelines on developing your project data management plan using: Renata G Curty. (2023). DMP Recommendations (DCC Template). Zenodo. https://doi.org/10.5281/zenodo.7566971"
  },
  {
    "objectID": "plan.html#data-management-plan-tool",
    "href": "plan.html#data-management-plan-tool",
    "title": "Data Management Plan",
    "section": "Data Management Plan Tool",
    "text": "Data Management Plan Tool\nThere is a tool that you can use to guide your process: the DMP Tool. It is a little bit like an online form on steroids. Note that you do not have to use this tool for your project, but from our experience, it provides good guidance for this process.\n\n(Almost) everything in one page: https://perma.cc/3HFE-6X7U (here for more handouts)\n\n\n\n\nGet started with the tool: http://dmptool.org/\nMake sure to create an account using your UCSB email!"
  },
  {
    "objectID": "plan.html#using-your-data-management-plan",
    "href": "plan.html#using-your-data-management-plan",
    "title": "Data Management Plan",
    "section": "Using your Data Management Plan",
    "text": "Using your Data Management Plan\nOk, you have a plan, now what!? A data management plan should be seen as a living document that you update as your project develops and data needs evolve. We thus recommend sharing this plan with all your team members and external partners when relevant. The DMP Tool has the capacity to share plans directly from the tool. If you do not choose to use it, we recommend choosing a file format that can be collectively edited and provide some versioning/track changes feature, such as Google Docs or other cloud-based storage and documents."
  },
  {
    "objectID": "plan.html#further-reading-recommendations",
    "href": "plan.html#further-reading-recommendations",
    "title": "Data Management Plan",
    "section": "Further Reading Recommendations",
    "text": "Further Reading Recommendations\n\nGood overview of Data management concepts: Arteaga Cuevas, Maria; Taylor, Shawna; and Narlock, Mikala. (2023). Introduction to Research Data Management for Researchers. Data Curation Network Primer for Researchers on how to Manage Data\nGood overview of the data lifecycle, including itemized checklist: https://osf.io/d8fqh"
  },
  {
    "objectID": "manage.html",
    "href": "manage.html",
    "title": "Managing your data",
    "section": "",
    "text": "While actively working on your project, there are several practices that can help you to manage your data in an efficient manner that will help you to collaborate with others (including your future self!) and make your work more reproducible."
  },
  {
    "objectID": "manage.html#track-your-data-sources",
    "href": "manage.html#track-your-data-sources",
    "title": "Managing your data",
    "section": "Track your data sources",
    "text": "Track your data sources\nAs you collect your data, if using pre-existing data sources, we strongly recommend that you keep track of where/by whom you accessed the data you will use. It can be a link to a data archive, an official agency website, or the contact information of a person. This data log can be developed using a spreadsheet that you can share with your team. The goal here is to make sure you can:\n\nGo back to the original source and the right version of the data\nCorrectly attribute/cite the data sources when you project\nReach out to data creators and ask for potential clarifications you might need to correctly interpret the data\nInquiry for any data updates at a later date"
  },
  {
    "objectID": "manage.html#keep-raw-data-raw",
    "href": "manage.html#keep-raw-data-raw",
    "title": "Managing your data",
    "section": "Keep raw data raw",
    "text": "Keep raw data raw\nDuring the data collection phase, also make sure to create a dedicated folder to save the raw data version you just acquired.\nIf you are using a programmatic approach to acquire your data (e.g., API), make sure to only read the raw data and save any processed intermediate data products in a different folder. We recommend changing the permissions on your raw data folder to read-only to avoid any unexpected incidents.\nIf you are accessing the data using a Graphical User Interface (GUI), we recommend you create a “working copy” of your raw data in a separate folder and use those files as it is often very easy to accidentally overwrite it."
  },
  {
    "objectID": "manage.html#project-organization",
    "href": "manage.html#project-organization",
    "title": "Managing your data",
    "section": "Project organization",
    "text": "Project organization\nWe recommend encapsulating your project into one folder. It will make it more portable when combined with a relative path and help you keep the information centralized in one place. Here is a starting point for your file structure with three subfolders:\n\nData: where you will store your data with the following file structure\n\nInput_data: to store the raw data you collected or/and are reusing\nIntermediate_data: to store any cleaned or merged data sets\nAnalysis_data: any model analytical outputs that you computed\n\nCode or Scripts: you can store your scripts in this folder. You can keep everything within the folder using filename to organize it or create subfolders as needed\nResults: to store tables, graphs, reports, or any other scientific products you are producing\n\nIn the top-level folder, we also recommend you write a README to explain your project, list the contributors and provide information on how to best navigate your project folder as well as a short description of the files it contains.\n\n\n\nSource: RDS Data Literacy Series\n\n\nOf course, each project is different, so adapt these recommendations to your own project needs!"
  },
  {
    "objectID": "manage.html#adopt-a-consistent-naming-convention",
    "href": "manage.html#adopt-a-consistent-naming-convention",
    "title": "Managing your data",
    "section": "Adopt a consistent naming convention",
    "text": "Adopt a consistent naming convention\nDevelop naming conventions for files and folders:\n\nAvoid spaces (use underscores or dashes)\nAvoid punctuation or special characters\nTry to leverage alphabetical order (e.g., start with dates: 2020-05-08)\nUse descriptive naming (lite metadata)\nUse folders to structure/organize content\nKeep it simple\nMake it programmatically useful:\n\nUseful to select files (Wildcard *, regular expression)\nBut don’t forget Humans need to read file names too!!\nTip: leverage the use of _ and - to make your filename readable by both Humans and machines!\n\n\n\nTry it:\nWhich filename would be the most useful?\n\n06-2020-08-sensor2-plot1.csv\n2020-05-08_light-sensor-1_plot-1.csv\nMeasurement 1.csv\n2020-05-08-light-sensor-1-plot-2.csv\n2020-05-08-windSensor1-plot3.csv\n\nRemember, the most important is to make it consistent!\nA good reference on this topic from Jenny Bryan (Posit)."
  },
  {
    "objectID": "manage.html#backup-your-data",
    "href": "manage.html#backup-your-data",
    "title": "Managing your data",
    "section": "Backup your data",
    "text": "Backup your data\nDon’t forget, things happen!!!\n\n\n\n\n\nTo protect yourself against data loss, we suggest you backup your data following the 3-2-1 rule:\n\nMaintain 3 up-to-date copies of your data\nIn 2 different storage solutions\nwith 1 copy being off-site or in the cloud\n\n\n\n\nSource: RDS Data Literacy Series\n\n\nAs a UCSB affiliate, you can access cloud storage solutions such as Google Drive and Box and other departmental computing and storage resources. Check with your departmental IT Team!"
  },
  {
    "objectID": "manage.html#making-your-work-more-reproducible",
    "href": "manage.html#making-your-work-more-reproducible",
    "title": "Managing your data",
    "section": "Making your work more reproducible",
    "text": "Making your work more reproducible\n\nAnalytical workflows\nBuilding analytical workflows or data pipelines empowers you to iterate more quickly and integrate new information more easily. Say goodbye to copy-paste!! It also enables others to build on your work. Your research is important – but arguably only when others can find it, make sense of it, and build from it. You’re constantly collaborating and, most importantly, with your Future self!. Develop your workflows in a mindset geared towards collaboration. ***Workflows are rarely linear!\n\n\n\nThe tidy workflow, Source: R for Data Science\n\n\nWorkflows are rarely linear! They are developed iteratively, and one of the most helpful things you can do is talk about them with your research team.\n\n\nCode\nOne great way to build such workflow from raw data to scientific outputs is to use scripts and leave copy-pasting behind. Here are a few things to consider:\n\nComment your code…too much is not a thing\nNotebooks like Jupyter and RMarkdown can help you to be more explicit by integrating outputs/results along with your code\nKeep things in sync in a centralized place online to avoid duplication (data, scripts, code…)\nCentralize your data in shared computing resources or data repositories\nUse version control software (e.g., Git) rather than your own bookkeeping methods (goodbye script_JM_03v5b.R)\nCode sharing and collaboration using code repository services (e.g., GitHub, GitLab, …)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About RDS",
    "section": "",
    "text": "Research Data Services (RDS) helps UCSB researchers manage and preserve their research data through:\n\nConsultations\nLong-term engagements\nInstructional workshops.\n\nOur team offers support across the research data lifecycle, from pre-project planning to post-project archival, connecting researchers with both locally- and externally-provided curation services. Our goal is to ensure that all research data is well-described, FAIR (Findable, Accessible, Interoperable, Reusable), and sustainably preservable, and that researchers receive scholarly credit for sharing and publishing data.\nContact us if you have any questions: rds@library.ucsb.edu"
  },
  {
    "objectID": "preserve.html",
    "href": "preserve.html",
    "title": "Archiving and preserving your data",
    "section": "",
    "text": "As you finalize your project, an important task is to archive your data in a publicly available repository (pending sensitivity and by non-disclosure agreement exceptions). There are a few important steps to ensure that your data can be reused by others and thus make your work more reproducible.\nYour general philosophy when preparing the preservation of your scientific products should be: Document what you used and preserve what you produced"
  },
  {
    "objectID": "preserve.html#what-scientific-products-to-preserve",
    "href": "preserve.html#what-scientific-products-to-preserve",
    "title": "Archiving and preserving your data",
    "section": "What scientific products to preserve?",
    "text": "What scientific products to preserve?\nOften the first question that comes to mind when starting to preserve your work is: What should I include in my data archive? Generally speaking, you want to preserve your work. This means capturing the methodology you used, the raw data you collected, any data cleaning you did, and any data and output (figure, report, etc.) you generated. Okay… so you mean everything!? Well, yes and no. Everything that was relevant to help you to come to the findings and conclusions discussed in your project report or any other publications and deliverables. Let’s break this down!\n\nRaw data\nHere are a few questions to ask yourself to determine if you should refer in your documentation to the raw data you used or also include them in your data archive.\n\nThe raw data is already publicly accessible, and the hosting solution (website, FTP server, etc.) seems well maintained (ideally providing a recommended citation)\n=&gt; Document the website or process you used to collect the data and when you accessed/downloaded the data you used. Try also to determine if a specific version number is associated with the data you used.\nThe raw data is not publicly accessible\nNote that we are not talking about data under a non-disclosure agreement (NDA) here but more about data with an unclear reuse status or obtained by interactions with a person or an institution. For example, if the data you used were sent to you privately, then we recommend that you:\n\ninquire with your person of contact about the status of licensing and if they would be willing to let you share those data publicly. You might face resistance at first, so take the time to explain why you think it is valuable to your work to also share those data sets.\nif, in the end, it is not possible to share the data, please still describe the data in your documentation and list the contact information (person or institution) to inquire about this data set.\n\n\n\n\nIntermediate data\nThis is data you generated either while cleaning or analyzing the raw data. You should preserve it if:\n\nit was not directly generated by a script (otherwise, preserve the code instead)\nit has reusable value. For example, cleaned-up versions of raw data can be very valuable for others to reuse!\n\n\n\nCode\nScripting your analytical workflow from the raw data to the end products is a great way to make your work more reproducible and more reusable by others. We thus strongly encourage your team to develop code to process and analyze data. Cloud-based code repository services, such as GitHub, GitLab, BitBucket, and more, are a great way to both manage and preserve your code.\nThose services are often well-integrated with data repositories that link your code repository with your data archive. They also offer a way to tag a specific version of your code to ensure it is the exact code you used for a specific analysis.\n\n\nFinal products\nWe recommend including any data set used to produce statistics, figures maps, and other visualizations that were used in your work, in this case, even if generated by scripts."
  },
  {
    "objectID": "preserve.html#choosing-a-data-repository",
    "href": "preserve.html#choosing-a-data-repository",
    "title": "Archiving and preserving your data",
    "section": "Choosing a data repository",
    "text": "Choosing a data repository\nOK, we know what we want to archive. Now let’s decide where we want to preserve things!\nUCSB’s institutional data repository Dryad will be your default data repository. However, we encourage you to discuss with your Faculty Advisor to determine if other data repositories might suit your targeted audience/community better. If you would like to research on your own which data repository could be best for your project, the Registry of Research Data Repositories is a great resource to do so.\n\nDryad\nDryad is free of use for any affiliated researcher. Here is an overview of the process of submitting data to DRYAD:\n\n\n\nDRYAD data submission overview\n\n\nBefore you can start this submission process, we will describe the information you need to prepare for your data archive submission."
  },
  {
    "objectID": "preserve.html#sharing-your-work",
    "href": "preserve.html#sharing-your-work",
    "title": "Archiving and preserving your data",
    "section": "Sharing your work",
    "text": "Sharing your work\n\nUse open file formats\nWe recommend using open and text-based file formats as much as possible to make your data more accessible. It removes the need to buy specific software to open your data and ensures that this format will remain readable in the longer term.\n\n\nChoosing a license\nThis can quickly become an overwhelming subject. In a nutshell, Creative Commons licenses are the ones that are favored to license data.\n\n\n\nFoter, CC BY-SA 3.0 https://creativecommons.org/licenses/by-sa/3.0, via Wikimedia Commons\n\n\nNote that data repositories often support a certain number of licenses, so this can be a parameter to help you choose which data repository you want to use. For example, DRAYD is licensing all its content under CC0, an equivalent to saying its content is in the public domain.\nIf you want to know more on how to best license your data, click here"
  },
  {
    "objectID": "preserve.html#documenting-your-work",
    "href": "preserve.html#documenting-your-work",
    "title": "Archiving and preserving your data",
    "section": "Documenting your work",
    "text": "Documenting your work\nTo make your archiving process the most efficient, it is key to document your work as you progress throughout your project. If you do so, archiving your data will consist of collecting existing information about the various parts of your project rather than developing it from scratch a few months after you have generated this specific data set.\nAdd an image about the power of README\n\nMetadata\nMetadata aims at describing your data with enough information that should let you be able to reuse this data even if you know nothing about this specific data set. It is sometimes defined as data about data. So what should you include? Here are some pointers:\n\nDescribe the contents of data files. If you are using complex jargon or concepts make sure you refer to external vocabulary or clearly define these terms as used in your project\nKeep data entry consistent\nDefine the parameters and the units on the parameter\nExplain the formats for date, time, geographic coordinates, and other parameters\nDefine any coded values or acronyms used (in the data or headers)\nDescribe quality flags or qualifying values\nDefine missing values\nAlways use an established metadata standard\n\nNote that there are existing metadata standards that can help you to structure your data in a systematic way. Some data repositories offer web forms that let you enter metadata information in a way that is compatible with those standards.\n\n\nREADME\nREADME files are not new; they have been around computer-based projects since the early days and have proven to be very valuable in describing content. For your main project README we recommend compiling the following information about your data:\n\nData sources: where did you get your raw data from?\nProvenance: what data set you used/combined to generate your new data\nLicense & permissions: state under which license your data sets are released so others know what they can do with your data\nMethodology: describe the methodology used for your projects\nData listing: list all your data and their potential relationships\nMetadata: add the metadata you developed earlier for each of your data set\n\nNote that you should not feel limited to one README only. It is a great practice to also have READMEs in any subfolder/section of your project with complex organization and explanations on how to navigate the file structure or in which order files should be combined.\nOur team has prepared a README template for your submission to Dryad. Note that some sections might not be relevant to your project, and you should simply delete those as you move through filling out this template."
  },
  {
    "objectID": "preserve.html#submitting-to-dryad",
    "href": "preserve.html#submitting-to-dryad",
    "title": "Archiving and preserving your data",
    "section": "Submitting to DRYAD",
    "text": "Submitting to DRYAD\nYou are now ready to start the submission process!! Here we are going to use DRYAD as an example.\n\nBefore logging into Dryad, you must create a free ORCID. ORCIDs are free, unique identifiers for yourself. Think of it as a Social Security Number for Researchers that, this time, you can share. Create your account here.\nThen you can login and should land on a page as below. Click on the Start new dataset button\n\n\n\nYou will now have to fill out the web form to provide project-level information, starting with the Preliminary information section. Select other or not applicable as your submission is not related to a journal publication.\n\n\n\nFill the Basic information section\n\nTitle: Note it can be different than your project a describing as much as possible your data archive content\nAuthors: enter all your teammates\nResearch domain: Choose the more relevant to your project\nFunding: check the No Funding received box or enter any external funding you received for this project\nAbstract: enter a short description of your work\n\nData Description section:\n\nKeywords: add relevant keywords and please make sure to add the Bren project keyword BrenMESMProject\nMethods: describe the methods you used for your analysis\nUsage notes: you can add any software you used to conduct your project here. please provide the version number along with the software name\n\nRelated work section:\n\nThis is where you can link your data repository on GitHub with your data archive. Select Software as Work type and paste the URL to your repository. Do not forget to also provide the necessary information on the README on your code repository. Once your data archive is published on DRYAD, do not forget to add the link to README on GitHub, linking the resources both ways.\n\n\n\nDRYAD full Submission and publication guidelines: https://datadryad.org/stash/submission_process"
  },
  {
    "objectID": "preserve.html#data-curation-process",
    "href": "preserve.html#data-curation-process",
    "title": "Archiving and preserving your data",
    "section": "Data curation process",
    "text": "Data curation process\nOK, you have submitted your data and its documentation to the DRYAD (or others) data repository, what is next!? Most of the data repository will have some level of data curation process, mainly a series of checks that will ensure that you provided all the necessary documentation to make your research work understandable to others. Some of those checks might be done automatically (leveraging metadata standards, for example), some others will be done by data curators associated with the data repository. In the coming days of your submission to DRYAD, a curator will reach out to you with a list of items to improve. For example replacing and Excel spreadsheets (proprietary software) with csv files that can be more easily open, especially in several years from now. Adding more information about the raw data you used or clarifying their licensing, provide more details about your methodology. Once this feedback received, you will have to iterate through those recommendations as needed and resubmit your updated documentation and data. You can expect the curation process to take several days to potentially a few weeks. Therefore plan accordingly!!"
  },
  {
    "objectID": "preserve.html#publication",
    "href": "preserve.html#publication",
    "title": "Archiving and preserving your data",
    "section": "Publication",
    "text": "Publication\nOnce the curation process is over, your data will be publish and made publicly available. Most of the data repository provide a DOI to reference your data archive. Use this DOI to share and cite your data archive in your project report and publications!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Data Management",
    "section": "",
    "text": "This website aims at helping graduate students conducting their first data-intensive project to plan and manage their data with a reproducible mindset.\nWe provide advice on:\n\nHow to develop your Data Management Plan (DMP)\nHow to manage and document your data to ease the preservation of your work, so others (including future-you) can reuse it.\nHow to preserve and share your data using a data repository\n\n\n\n\nResearch Data Management lifecycle; source: https://osf.io/d8fqh\n\n\n\n\n\nCitationBibTeX citation:@online{brun2024,\n  author = {Brun, Julien and Curty, Renata and Janée, Greg},\n  title = {Project {Data} {Management}},\n  date = {2024-04-25},\n  url = {https://ucsb-library-research-data-services.github.io/project-data-management/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBrun, Julien, Renata Curty, and Greg Janée. 2024. “Project Data\nManagement.” April 25, 2024. https://ucsb-library-research-data-services.github.io/project-data-management/."
  }
]